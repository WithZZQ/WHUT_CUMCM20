{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================Test===================\n",
      "[['1'], ['I1'], ['I2'], ['I5'], ['I4'], ['5'], ['I3'], ['1', 'I1'], ['1', 'I2'], ['I1', 'I2'], ['I1', 'I5'], ['I2', 'I5'], ['1', 'I4'], ['I2', 'I4'], ['I2', 'I3'], ['5', 'I2'], ['5', 'I3'], ['I1', 'I3'], ['1', 'I1', 'I2'], ['I1', 'I2', 'I5'], ['1', 'I2', 'I4'], ['5', 'I2', 'I3'], ['I1', 'I2', 'I3']]\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding:utf-8 -*-\n",
    "#code write by guohao\n",
    " \n",
    "import itertools\n",
    " \n",
    "class Apriori(object):\n",
    "    \n",
    "    def __init__(self,min_sup=0.2,dataDic={}):\n",
    "        self.data = dataDic      #构建数据记录词典\n",
    "        self.size = len(dataDic) #统计事务个数\n",
    "        self.min_sup = min_sup   #最小支持度阈值\n",
    "        self.min_sup_val = min_sup * self.size  #最小支持度计数\n",
    " \n",
    "    def find_frequent_1_itemsets(self):\n",
    "        FreqDic = {}   #用于统计物品的支持度计数\n",
    "        for event in self.data:    #event为每一条记录\n",
    "            for item in self.data[event]:   #item为项\n",
    "                if item in FreqDic:\n",
    "                    FreqDic[item] += 1\n",
    "                else:\n",
    "                    FreqDic[item] = 1\n",
    " \n",
    "        L1 = []\n",
    "        for itemset in FreqDic:\n",
    "            if FreqDic[itemset] >=self.min_sup_val:  #过滤掉小于最小支持度计数的1-项集\n",
    "                L1.append([itemset])\n",
    "        return L1\n",
    " \n",
    "    def has_infrequent_subset(self,c,L_last,k):\n",
    "        #c为当前集合，L_last为上一个频繁项集的集合，k为当前频繁项集内的元素个数\n",
    "        #该函数用于检查当前子集是否都为频繁项集\n",
    "        subsets = list(itertools.combinations(c,k-1))\n",
    "        for each in subsets:\n",
    "            each = list(each)\n",
    "            if each not in L_last:\n",
    "                return True\n",
    "        return False\n",
    " \n",
    "    def apriori_gen(self,L_last):  #连接步实现\n",
    "        k = len(L_last[0]) + 1\n",
    "        Ck = []\n",
    "        for itemset1 in L_last:\n",
    "            for itemset2 in L_last:\n",
    "                flag = 0\n",
    "                for i in range(k-2):\n",
    "                    if itemset1[i] != itemset2[i]:    #如果前k-2项中有一项不相等，则合并的项集必定不为频繁项集\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 1:continue\n",
    "                if itemset1[k-2] < itemset2[k-2]:\n",
    "                    c = itemset1 + [itemset2[k-2]]    #合成待定k项集\n",
    "                else:\n",
    "                    continue\n",
    " \n",
    "                if self.has_infrequent_subset(c,L_last,k):  #判断是否为1-项集\n",
    "                    continue\n",
    "                else:\n",
    "                    Ck.append(c)\n",
    "        return Ck\n",
    " \n",
    "    def do(self):\n",
    "        L_last = self.find_frequent_1_itemsets()   #找到频繁一项集\n",
    "        L = L_last\n",
    "        i = 0\n",
    "        while L_last != []:\n",
    "            Ck = self.apriori_gen(L_last)      #合并形成新的待定频繁项集\n",
    "            FreqDic = {}         #项集的频数集合\n",
    "            for event in self.data:\n",
    "                for c in Ck:    \n",
    "                    if set(c) <= set(self.data[event]): #判断新合成的频繁集是否是事务记录的子集\n",
    "                        if tuple(c) in FreqDic:\n",
    "                            FreqDic[tuple(c)] += 1\n",
    "                        else:\n",
    "                            FreqDic[tuple(c)] = 1\n",
    "            Lk = []\n",
    "            for c in FreqDic:\n",
    "                if FreqDic[c] > self.min_sup_val: #判断新形成的待定频繁项集是否为为真正的频繁项集\n",
    "                    Lk.append(list(c))\n",
    "            L_last = Lk\n",
    "            L += Lk\n",
    "        return L\n",
    " \n",
    " \n",
    " \n",
    "#*****************************Test*****************************\n",
    "print('======================Test===================')\n",
    "Data = {'T100':['1','I1','I2','I5'],\n",
    "        'T200':['1','I2','I4'],\n",
    "        'T300':['5','I2','I3'],\n",
    "        'T400':['1','I1','I2','I4'],\n",
    "        'T500':['5','I1','I3'],\n",
    "        'T600':['5','I2','I3'],\n",
    "        'T700':['3','I1','I3'],\n",
    "        'T800':['4','I1','I2','I3','I5'],\n",
    "        'T900':['1','I1','I2','I3']}\n",
    " \n",
    "a = Apriori(dataDic = Data)\n",
    "print(a.do())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#数据导入\n",
    "file_path = './Problem_C_Data/hair_dryer.tsv'\n",
    "df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "df.head()\n",
    "\n",
    "df['Helpful %'] = np.where(df['helpful_votes'] > 0, df['helpful_votes'] / df['total_votes'], -1)\n",
    "df['% Upvote'] = pd.cut(df['Helpful %'], bins = [-1, 0, 0.2, 0.4, 0.6, 0.8, 1.0], labels = ['Empty', '0-20%', '20-40%', '40-60%', '60-80%', '80-100%'], include_lowest = True)\n",
    "df.head()\n",
    "\n",
    "df_s = df.groupby(['star_rating', '% Upvote']).agg({'review_id': 'count'})\n",
    "df_s = df_s.unstack()\n",
    "df_s.columns = df_s.columns.get_level_values(1)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "#保留不是3的评论\n",
    "filtered_data = df[df['star_rating'] != 3]\n",
    "def partition(x):\n",
    "    if x>3:\n",
    "        return 'positive'\n",
    "    return 'negative'\n",
    "\n",
    "actual_score = filtered_data['star_rating']\n",
    "positiveNegative = actual_score.map(partition)\n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10471, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10471, 19)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sorting data points according to the 'ProductId'\n",
    "sorted_data = filtered_data.sort_values('product_id', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "# Eliminating the duplicate data points based on: 'UserId', 'ProfileName', 'Time', 'Summary'\n",
    "final = sorted_data.drop_duplicates(subset={'review_id', 'product_title', 'review_date', 'review_body'}, keep='first', inplace=False)\n",
    "\n",
    "# Eliminating the row where 'HelpfulnessDenominator' is greater than 'HelpfulnessNumerator' as these are the wrong entry\n",
    "final = final[final['total_votes'] >= final['helpful_votes']]\n",
    "\n",
    "# Getting shape of final data frame\n",
    "display(final.shape)\n",
    "\n",
    "\n",
    "# Creating the set of stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# For stemming purpose\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "# Defining function to clean html tags\n",
    "def cleanhtml(sentence):\n",
    "    cleaner = re.compile('<.*>')\n",
    "    cleantext = re.sub(cleaner, ' ', sentence)\n",
    "    return cleantext\n",
    "\n",
    "# Defining function to remove special symbols\n",
    "def cleanpunc(sentence):\n",
    "    cleaned = re.sub(r'[?|.|!|*|@|#|\\'|\"|,|)|(|\\|/]', r'', sentence)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# Important steps to clean the text data. Please trace it out carefully\n",
    "i = 0\n",
    "str1 = ''\n",
    "all_positive_words = []\n",
    "all_negative_words = []\n",
    "final_string = []\n",
    "s=''\n",
    "for sent in final['review_body'].values:\n",
    "    filtered_sentence = []\n",
    "    sent = cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if ((cleaned_words.isalpha()) & (len(cleaned_words)>2)):\n",
    "                if (cleaned_words.lower() not in stop):\n",
    "                    s = (snow.stem(cleaned_words.lower())).encode('utf-8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive':\n",
    "                        all_positive_words.append(s)\n",
    "                    if (final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "    str1 = b\" \".join(filtered_sentence)\n",
    "    final_string.append(str1)\n",
    "    i += 1\n",
    "    \n",
    "# Adding new column into dataframe to store cleaned text\n",
    "final['CleanedText'] = final_string\n",
    "final['CleanedText'] = final['CleanedText'].str.decode('utf-8')\n",
    "\n",
    "\n",
    "# Getting shape of new datset\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 7860\n",
      "# train records: 7853\n",
      "# test records: 2618\n",
      "Model Accuracy: 0.9297173414820473\n",
      "\n",
      "-Top 20 positive-\n",
      "      Word  Coefficient\n",
      "      love     2.020178\n",
      "     excel     1.967720\n",
      "   perfect     1.775876\n",
      "     great     1.734631\n",
      " complaint     1.727514\n",
      "   definit     1.698679\n",
      "    awesom     1.633642\n",
      "      best     1.612823\n",
      "      tire     1.525653\n",
      "      easi     1.464901\n",
      "      nice     1.430808\n",
      "      amaz     1.403347\n",
      "     final     1.308430\n",
      "       bit     1.303979\n",
      "      fast     1.259788\n",
      "      glad     1.256158\n",
      "   compact     1.234372\n",
      "   quieter     1.218967\n",
      "     hesit     1.210404\n",
      "     fabul     1.209890\n",
      "\n",
      "-Top 20 negative-\n",
      "       Word  Coefficient\n",
      "    special    -1.350388\n",
      "   descript    -1.365947\n",
      "    useless    -1.390985\n",
      "      stuck    -1.415986\n",
      "      worst    -1.464123\n",
      "       slow    -1.465845\n",
      "      smoke    -1.528165\n",
      "   arthriti    -1.543483\n",
      "      broke    -1.567801\n",
      "       poor    -1.595778\n",
      "     defect    -1.612045\n",
      "      spark    -1.617485\n",
      "      month    -1.646086\n",
      "       fail    -1.679773\n",
      "       suck    -1.695555\n",
      "       junk    -1.736096\n",
      "       wast    -1.935428\n",
      " disappoint    -1.985671\n",
      "     return    -2.645736\n",
      "       stop    -2.655619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = final['CleanedText']\n",
    "y_dict = {1:0, 2:0, 4:1, 5:1}\n",
    "y = final['star_rating'].map(y_dict)\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "mpl.rcParams['font.size']=12                #10 \n",
    "mpl.rcParams['savefig.dpi']=100             #72 \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 \n",
    "\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=300,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin; it was heads\n",
    "        \n",
    "    ).generate(str(data))\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(15, 15))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "c = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "def text_fit(X, y, model,clf_model,coef_show=1):\n",
    "    \n",
    "    X_c = model.fit_transform(X)\n",
    "    print('# features: {}'.format(X_c.shape[1]))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0)\n",
    "    print('# train records: {}'.format(X_train.shape[0]))\n",
    "    print('# test records: {}'.format(X_test.shape[0]))\n",
    "    clf = clf_model.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print ('Model Accuracy: {}'.format(acc))\n",
    "\n",
    "    if coef_show == 1: \n",
    "        w = model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('-Top 20 positive-')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('-Top 20 negative-')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "    return coeff_df\n",
    "    \n",
    "    \n",
    "coeff_df = text_fit(X, y, c, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>love</td>\n",
       "      <td>2.020178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2305</td>\n",
       "      <td>excel</td>\n",
       "      <td>1.967720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4890</td>\n",
       "      <td>perfect</td>\n",
       "      <td>1.775876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2939</td>\n",
       "      <td>great</td>\n",
       "      <td>1.734631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1235</td>\n",
       "      <td>complaint</td>\n",
       "      <td>1.727514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Coefficient\n",
       "4010       love     2.020178\n",
       "2305      excel     1.967720\n",
       "4890    perfect     1.775876\n",
       "2939      great     1.734631\n",
       "1235  complaint     1.727514"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>Helpful %</th>\n",
       "      <th>% Upvote</th>\n",
       "      <th>Score</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10544</td>\n",
       "      <td>US</td>\n",
       "      <td>42867423</td>\n",
       "      <td>R3ATOPWDJHVDMG</td>\n",
       "      <td>B000052YD1</td>\n",
       "      <td>548212381</td>\n",
       "      <td>Colgate Peroxyl, Mouth Sore Rinse (Hydrogen Pe...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Peroxyl</td>\n",
       "      <td>Peroxyl isn't available where I live. The ship...</td>\n",
       "      <td>3/11/2010</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>40-60%</td>\n",
       "      <td>positive</td>\n",
       "      <td>peroxyl isnt avail live shipment slower expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10309</td>\n",
       "      <td>US</td>\n",
       "      <td>49919466</td>\n",
       "      <td>R1UW4UPNZR9SWU</td>\n",
       "      <td>B00005351F</td>\n",
       "      <td>138665286</td>\n",
       "      <td>OneTouch Penlet Plus, Adjustable Blood Sampler...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great!</td>\n",
       "      <td>My last penlet died pretty quickly. This one s...</td>\n",
       "      <td>8/5/2010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80-100%</td>\n",
       "      <td>positive</td>\n",
       "      <td>last penlet die pretti quick one seem lot soli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10492</td>\n",
       "      <td>US</td>\n",
       "      <td>19498472</td>\n",
       "      <td>R3VSUTOD2WZC0Y</td>\n",
       "      <td>B00005JG0H</td>\n",
       "      <td>801741616</td>\n",
       "      <td>Neutrogena MoistureShine Gloss, Whisper 05, 0....</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Always try Amazon 1st</td>\n",
       "      <td>Product is a nice beigey gloss,cannot find it ...</td>\n",
       "      <td>5/7/2010</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>positive</td>\n",
       "      <td>product nice beigey glosscannot find store any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11287</td>\n",
       "      <td>US</td>\n",
       "      <td>53095860</td>\n",
       "      <td>R172BY1R9FMJV4</td>\n",
       "      <td>B00005JS5G</td>\n",
       "      <td>297404894</td>\n",
       "      <td>Panasonic ER389K Rechargeable Beard and Mustac...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>My previous ER389 lasted 2 years</td>\n",
       "      <td>I just ordered a new ER389 because my current ...</td>\n",
       "      <td>4/15/2007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80-100%</td>\n",
       "      <td>negative</td>\n",
       "      <td>order new current one die littl two year use n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11468</td>\n",
       "      <td>US</td>\n",
       "      <td>38947355</td>\n",
       "      <td>R3JMGN42OJCL97</td>\n",
       "      <td>B00005O0MZ</td>\n",
       "      <td>694290590</td>\n",
       "      <td>conair corp pers care 146np conair ionic condi...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Excellent for fine/limp hair</td>\n",
       "      <td>This hairdryer far exceeded my expection for&lt;B...</td>\n",
       "      <td>4/20/2002</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>80-100%</td>\n",
       "      <td>positive</td>\n",
       "      <td>hairdryer far exceed expect high recommend fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>US</td>\n",
       "      <td>26613163</td>\n",
       "      <td>R2ZDX4VBVP18RX</td>\n",
       "      <td>B00VRN7SB8</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Sleek</td>\n",
       "      <td>My hairdryer was noisy and past its prime, so ...</td>\n",
       "      <td>8/16/2015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>positive</td>\n",
       "      <td>hairdryer noisi past prime delight tri new rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>US</td>\n",
       "      <td>52925627</td>\n",
       "      <td>R3MJ1HRSNHKFLJ</td>\n",
       "      <td>B00VRN7SB8</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Wonderful hair dryer for my road trip.</td>\n",
       "      <td>I'm on the road vacationing and brought this d...</td>\n",
       "      <td>8/16/2015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>positive</td>\n",
       "      <td>road vacat brought dryer long hair swim lot ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>US</td>\n",
       "      <td>48428870</td>\n",
       "      <td>R2AVR4LDQJ9ZC3</td>\n",
       "      <td>B00VRN7SB8</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Really nice features in a blower dryer</td>\n",
       "      <td>This is a very nice hair blow dryer.  The colo...</td>\n",
       "      <td>8/26/2015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>positive</td>\n",
       "      <td>nice hair blow dryer color love medium shade p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>US</td>\n",
       "      <td>52490536</td>\n",
       "      <td>R3MIW0NWXHCZCU</td>\n",
       "      <td>B00VRN7SB8</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Uncomfortably heavy</td>\n",
       "      <td>This blow dryer arrived compliments of the Vin...</td>\n",
       "      <td>8/4/2015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>negative</td>\n",
       "      <td>blow dryer arriv compliment vine program suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>US</td>\n",
       "      <td>32900509</td>\n",
       "      <td>R15121XDJ0ZIHH</td>\n",
       "      <td>B00VRN7SB8</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Quiet and powerful, but buttons could be bette...</td>\n",
       "      <td>Excellent hair dryer, but my impression is tha...</td>\n",
       "      <td>8/8/2015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>Empty</td>\n",
       "      <td>positive</td>\n",
       "      <td>excel hair dryer impress control could littl e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10471 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "10544          US     42867423  R3ATOPWDJHVDMG  B000052YD1       548212381   \n",
       "10309          US     49919466  R1UW4UPNZR9SWU  B00005351F       138665286   \n",
       "10492          US     19498472  R3VSUTOD2WZC0Y  B00005JG0H       801741616   \n",
       "11287          US     53095860  R172BY1R9FMJV4  B00005JS5G       297404894   \n",
       "11468          US     38947355  R3JMGN42OJCL97  B00005O0MZ       694290590   \n",
       "...           ...          ...             ...         ...             ...   \n",
       "181            US     26613163  R2ZDX4VBVP18RX  B00VRN7SB8       253917972   \n",
       "180            US     52925627  R3MJ1HRSNHKFLJ  B00VRN7SB8       253917972   \n",
       "51             US     48428870  R2AVR4LDQJ9ZC3  B00VRN7SB8       253917972   \n",
       "344            US     52490536  R3MIW0NWXHCZCU  B00VRN7SB8       253917972   \n",
       "281            US     32900509  R15121XDJ0ZIHH  B00VRN7SB8       253917972   \n",
       "\n",
       "                                           product_title product_category  \\\n",
       "10544  Colgate Peroxyl, Mouth Sore Rinse (Hydrogen Pe...           Beauty   \n",
       "10309  OneTouch Penlet Plus, Adjustable Blood Sampler...           Beauty   \n",
       "10492  Neutrogena MoistureShine Gloss, Whisper 05, 0....           Beauty   \n",
       "11287  Panasonic ER389K Rechargeable Beard and Mustac...           Beauty   \n",
       "11468  conair corp pers care 146np conair ionic condi...           Beauty   \n",
       "...                                                  ...              ...   \n",
       "181       remington silk ceramic professional hair dryer           Beauty   \n",
       "180       remington silk ceramic professional hair dryer           Beauty   \n",
       "51        remington silk ceramic professional hair dryer           Beauty   \n",
       "344       remington silk ceramic professional hair dryer           Beauty   \n",
       "281       remington silk ceramic professional hair dryer           Beauty   \n",
       "\n",
       "       star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "10544            5              3            6    N                 Y   \n",
       "10309            4              2            2    N                 Y   \n",
       "10492            5              0            0    N                 Y   \n",
       "11287            2              3            3    N                 N   \n",
       "11468            5             78           87    N                 N   \n",
       "...            ...            ...          ...  ...               ...   \n",
       "181              5              0            1    Y                 N   \n",
       "180              5              0            1    Y                 N   \n",
       "51               5              0            0    Y                 N   \n",
       "344              2              0            0    Y                 N   \n",
       "281              4              0            1    Y                 N   \n",
       "\n",
       "                                         review_headline  \\\n",
       "10544                                            Peroxyl   \n",
       "10309                                             Great!   \n",
       "10492                              Always try Amazon 1st   \n",
       "11287                   My previous ER389 lasted 2 years   \n",
       "11468                       Excellent for fine/limp hair   \n",
       "...                                                  ...   \n",
       "181                                                Sleek   \n",
       "180               Wonderful hair dryer for my road trip.   \n",
       "51                Really nice features in a blower dryer   \n",
       "344                                  Uncomfortably heavy   \n",
       "281    Quiet and powerful, but buttons could be bette...   \n",
       "\n",
       "                                             review_body review_date  \\\n",
       "10544  Peroxyl isn't available where I live. The ship...   3/11/2010   \n",
       "10309  My last penlet died pretty quickly. This one s...    8/5/2010   \n",
       "10492  Product is a nice beigey gloss,cannot find it ...    5/7/2010   \n",
       "11287  I just ordered a new ER389 because my current ...   4/15/2007   \n",
       "11468  This hairdryer far exceeded my expection for<B...   4/20/2002   \n",
       "...                                                  ...         ...   \n",
       "181    My hairdryer was noisy and past its prime, so ...   8/16/2015   \n",
       "180    I'm on the road vacationing and brought this d...   8/16/2015   \n",
       "51     This is a very nice hair blow dryer.  The colo...   8/26/2015   \n",
       "344    This blow dryer arrived compliments of the Vin...    8/4/2015   \n",
       "281    Excellent hair dryer, but my impression is tha...    8/8/2015   \n",
       "\n",
       "       Helpful % % Upvote     Score  \\\n",
       "10544   0.500000   40-60%  positive   \n",
       "10309   1.000000  80-100%  positive   \n",
       "10492  -1.000000    Empty  positive   \n",
       "11287   1.000000  80-100%  negative   \n",
       "11468   0.896552  80-100%  positive   \n",
       "...          ...      ...       ...   \n",
       "181    -1.000000    Empty  positive   \n",
       "180    -1.000000    Empty  positive   \n",
       "51     -1.000000    Empty  positive   \n",
       "344    -1.000000    Empty  negative   \n",
       "281    -1.000000    Empty  positive   \n",
       "\n",
       "                                             CleanedText  \n",
       "10544  peroxyl isnt avail live shipment slower expect...  \n",
       "10309  last penlet die pretti quick one seem lot soli...  \n",
       "10492  product nice beigey glosscannot find store any...  \n",
       "11287  order new current one die littl two year use n...  \n",
       "11468  hairdryer far exceed expect high recommend fin...  \n",
       "...                                                  ...  \n",
       "181    hairdryer noisi past prime delight tri new rem...  \n",
       "180    road vacat brought dryer long hair swim lot ch...  \n",
       "51     nice hair blow dryer color love medium shade p...  \n",
       "344    blow dryer arriv compliment vine program suppo...  \n",
       "281    excel hair dryer impress control could littl e...  \n",
       "\n",
       "[10471 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_id = final['product_id']\n",
    "CleanedText = final['CleanedText']\n",
    "Score = final['final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
